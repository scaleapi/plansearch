{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdownify import markdownify as md\n",
    "from markdownify import MarkdownConverter\n",
    "\n",
    "import os\n",
    "os.environ[\"EXECUTOR_URL\"] = \"***REMOVED***\"\n",
    "os.environ[\"EXECUTOR_AUTH\"] = \"***REMOVED***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "import re\n",
    "\n",
    "def get_codeforces_problem(contest_id, problem_index):\n",
    "    api_url = f\"https://codeforces.com/api/contest.standings?contestId={contest_id}&from=1&count=1&showUnofficial=true\"\n",
    "    response = requests.get(api_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to fetch the problem. Status code: {response.status_code}\"\n",
    "    \n",
    "    data = response.json()\n",
    "    if data['status'] != 'OK':\n",
    "        return f\"API error: {data['comment']}\"\n",
    "    \n",
    "    problems = data['result']['problems']\n",
    "    problem = next((p for p in problems if p['index'] == problem_index), None)\n",
    "    \n",
    "    if not problem:\n",
    "        return f\"Problem {problem_index} not found in contest {contest_id}\"\n",
    "    \n",
    "    problem_data = {\n",
    "        'name': f\"{problem['index']}. {problem['name']}\",\n",
    "        'rating': problem.get('rating', 'Not rated'),\n",
    "        'tags': problem.get('tags', [])\n",
    "    }\n",
    "    \n",
    "    # Fetch problem statement and samples\n",
    "    problem_url = f\"https://codeforces.com/contest/{contest_id}/problem/{problem_index}\"\n",
    "    response = requests.get(problem_url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return f\"Failed to fetch problem details. Status code: {response.status_code}\"\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    problem_statement = soup.find('div', class_='problem-statement')\n",
    "    \n",
    "    if problem_statement:\n",
    "        # Extract the second direct child div in \"problem-statement\" and join paragraphs with double newlines\n",
    "        problem_statement_divs = problem_statement.find_all('div', recursive=False)\n",
    "        if len(problem_statement_divs) > 1:\n",
    "            second_div = problem_statement_divs[1]\n",
    "            problem_data[\"statement\"] = MarkdownConverter().convert_soup(second_div)\n",
    "            problem_data['statement'] = re.sub(r'\\$\\$\\$(.*?)\\$\\$\\$', r'\\1', problem_data['statement'])  # Remove LaTeX dollar signs\n",
    "        else:\n",
    "            problem_data['statement'] = \"Statement not found\"\n",
    "        # Parse time limit\n",
    "        time_limit_text = problem_statement.find('div', class_='time-limit').text.strip()\n",
    "        time_limit_match = re.search(r'(\\d+) second', time_limit_text)\n",
    "        if time_limit_match:\n",
    "            problem_data['time_limit'] = int(time_limit_match.group(1))\n",
    "        else:\n",
    "            problem_data['time_limit'] = None\n",
    "        \n",
    "        input_spec = problem_statement.find('div', class_='input-specification')\n",
    "        output_spec = problem_statement.find('div', class_='output-specification')\n",
    "        notes = problem_statement.find('div', class_='note')\n",
    "\n",
    "        problem_data['input_spec'] = MarkdownConverter().convert_soup(input_spec) if input_spec else \"Not specified\"\n",
    "        problem_data['input_spec'] = re.sub(r'\\$\\$\\$(.*?)\\$\\$\\$', r'\\1', problem_data['input_spec'])  # Remove LaTeX dollar signs\n",
    "        problem_data['output_spec'] = MarkdownConverter().convert_soup(output_spec) if output_spec else \"Not specified\"\n",
    "        problem_data['output_spec'] = re.sub(r'\\$\\$\\$(.*?)\\$\\$\\$', r'\\1', problem_data['output_spec'])  # Remove LaTeX dollar signs\n",
    "        problem_data['note'] = MarkdownConverter().convert_soup(notes) if notes else \"\"\n",
    "        problem_data['note'] = re.sub(r'\\$\\$\\$(.*?)\\$\\$\\$', r'\\1', problem_data['note'])  # Remove LaTeX dollar signs\n",
    "\n",
    "        # Remove extra \"Input\" and \"Output\" headings\n",
    "        problem_data['input_spec'] = re.sub(r'^Input', '', problem_data['input_spec']).strip()\n",
    "        problem_data['output_spec'] = re.sub(r'^Output', '', problem_data['output_spec']).strip()\n",
    "        sample_test = problem_statement.find('div', class_='sample-test')\n",
    "        problem_data['samples'] = []\n",
    "      \n",
    "        input_divs = sample_test.find_all('div', class_='input')\n",
    "        output_divs = sample_test.find_all('div', class_='output')\n",
    "        \n",
    "        for input_div, output_div in zip(input_divs, output_divs):\n",
    "            # Process input data\n",
    "            input_lines = input_div.find('pre').find_all('div', class_='test-example-line')\n",
    "            input_data = '\\n'.join(html.unescape(line.text.strip()) for line in input_lines)\n",
    "            \n",
    "            # Process output data\n",
    "            output_data = output_div.find('pre').text.strip()\n",
    "            output_data = html.unescape(output_data)\n",
    "            \n",
    "            problem_data['samples'].append({'input': input_data + \"\\n\", 'output': output_data + \"\\n\"})\n",
    "       \n",
    "        # Combine into problem_str\n",
    "        problem_str = f\"{problem_data['statement']}\\n\\nInput\\n\\n{problem_data['input_spec']}\\n\\nOutput\\n\\n{problem_data['output_spec']}\\n\\n\"\n",
    "        for i, sample in enumerate(problem_data['samples']):\n",
    "            problem_str += f\"Sample Input {i + 1}\\n\\n{sample['input']}\\nSample Output {i + 1}\\n\\n{sample['output']}\\n\"\n",
    "        problem_str += problem_data['note']\n",
    "        problem_data['problem_str'] = problem_str.strip()\n",
    "    \n",
    "    return problem_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from base_classes import Problem, Test\n",
    "\n",
    "contest_id = 1992\n",
    "problem_index = \"B\"\n",
    "problem_info = get_codeforces_problem(contest_id, problem_index)\n",
    "\n",
    "public_tests = [Test(([sample[\"input\"]], {}), sample[\"output\"], None) for sample in problem_info[\"samples\"]]\n",
    "to_solve = Problem(problem_info[\"problem_str\"], None, public_tests, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from basic_prompting import SimplePromptModel \n",
    "from simple_idea_model import SimpleIdeaModel\n",
    "from simple_filter_models import SimpleFilteringModel\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "experiment_directory = f\"codeforces/logs/{contest_id}_{problem_index}_{datetime.datetime.now().strftime('%m-%dT%H:%M:%S')}\"\n",
    "save_path = os.path.join(experiment_directory, \"output.py\")\n",
    "model = SimpleIdeaModel(idea_model=\"gpt-4-turbo\", code_model=\"gpt-4-turbo\", experiment_directory=experiment_directory, cache_file=\"codeforces/cache.json\", idea_temperature=0.5, code_temperature=0.5)\n",
    "model = SimpleFilteringModel(\"filtering\", experiment_directory, \"codeforces/cache.json\", model)\n",
    "# Make the directory if it doesn't exist\n",
    "Path(experiment_directory).mkdir(parents=True, exist_ok=True)\n",
    "out_code = model.generate_solutions([to_solve])[0]\n",
    "out_code += \"\\n#\\n\"\n",
    "\n",
    "with open(save_path, \"w\") as f:\n",
    "    f.write(out_code)\n",
    "print(save_path)\n",
    "\n",
    "print(f\"{os.path.abspath(save_path)}\")  # Add this line to display the full file path\n",
    "\n",
    "from IPython.display import FileLink\n",
    "# Display a link to download the file\n",
    "print(FileLink(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exec_utils import run_tests\n",
    "run_tests(out_code, public_tests, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cf submit -f {save_path} {contest_id}{problem_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlxf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
