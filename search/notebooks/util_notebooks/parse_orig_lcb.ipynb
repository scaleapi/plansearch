{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapted From CodeRM (Federico Cassano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import json\n",
    "import pickle\n",
    "import zlib\n",
    "import base64\n",
    "\n",
    "\n",
    "def parse_date(date):\n",
    "    date_format = '%Y-%m-%dT%H:%M:%S'\n",
    "    return datetime.datetime.strptime(date, date_format)\n",
    "import datetime\n",
    "sonnet_cutoff = datetime.datetime(2023, 9, 30, 0, 0)\n",
    "\n",
    "def decode_tests(tests):\n",
    "    return json.loads(\n",
    "                pickle.loads(\n",
    "                    zlib.decompress(\n",
    "                        base64.b64decode(tests)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "# format we want:\n",
    "# - question: has prompt\n",
    "# - starter_code: has starter code, if any\n",
    "# - difficulty: has difficulty\n",
    "# - input_output: has tests, with fn_name key if needed\n",
    "# - title: just for metadata\n",
    "# - source: just for metadata\n",
    "# - date: just for metadata\n",
    "# - id: for unique id\n",
    "\n",
    "def clean_and_push(ds, reponame):\n",
    "    cleaned_ds = []\n",
    "    for ex in tqdm(ds, total=len(ds)):\n",
    "        public_raw_tests = json.loads(ex[\"public_test_cases\"])\n",
    "        raw_tests = decode_tests(ex[\"private_test_cases\"]) + public_raw_tests\n",
    "        tests = {\"inputs\": [], \"outputs\": []}\n",
    "        public_tests = {\"inputs\": [], \"outputs\": []}\n",
    "        metadata = json.loads(ex[\"metadata\"])\n",
    "        \n",
    "        for test in raw_tests:\n",
    "            inp = test[\"input\"]\n",
    "            out = test[\"output\"]\n",
    "            \n",
    "            if \"func_name\" in metadata:\n",
    "                inp = [json.loads(i) for i in inp.split(\"\\n\")]\n",
    "                out = json.loads(out)\n",
    "            \n",
    "            tests[\"inputs\"].append(inp)\n",
    "            tests[\"outputs\"].append(out)\n",
    "\n",
    "        for test in public_raw_tests:\n",
    "            inp = test[\"input\"]\n",
    "            out = test[\"output\"]\n",
    "            \n",
    "            if \"func_name\" in metadata:\n",
    "                inp = [json.loads(i) for i in inp.split(\"\\n\")]\n",
    "                out = json.loads(out)\n",
    "            \n",
    "            public_tests[\"inputs\"].append(inp)\n",
    "            public_tests[\"outputs\"].append(out)\n",
    "    \n",
    "        if \"func_name\" in metadata:\n",
    "            name = metadata[\"func_name\"]\n",
    "            tests[\"fn_name\"] = name\n",
    "            public_tests[\"fn_name\"] = name\n",
    "            \n",
    "        \n",
    "        obj = {\n",
    "            \"question\": ex[\"question_content\"],\n",
    "            \"starter_code\": ex[\"starter_code\"],\n",
    "            \"difficulty\": ex[\"difficulty\"],\n",
    "            \"input_output\": json.dumps(tests),\n",
    "            \"public_input_output\": json.dumps(public_tests),\n",
    "            \"title\": ex[\"question_title\"],\n",
    "            \"source\": ex[\"platform\"],\n",
    "            \"date\": ex[\"contest_date\"],\n",
    "            \"id\": ex[\"question_id\"],\n",
    "        }\n",
    "        cleaned_ds.append(obj)\n",
    "        \n",
    "    cleaned_ds = datasets.Dataset.from_list(cleaned_ds)\n",
    "    print(\"pushing to: \", reponame)\n",
    "    cleaned_ds.push_to_hub(reponame, split=\"test\", private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(\"livecodebench/code_generation_lite\", split=\"test\", version_tag=\"release_v3\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet_cutoff = datetime.datetime(2024, 4, 1, 0, 0)\n",
    "ds_decont = ds.filter(lambda ex: parse_date(ex[\"contest_date\"]) >= sonnet_cutoff)\n",
    "ds_decont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_push(ds_decont, \"codegenning/livecodebench_lite_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_C = ds.filter(lambda ex: parse_date(ex[\"contest_date\"]) < sonnet_cutoff)\n",
    "ds_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_and_push(ds_C, \"codegenning/livecodebench_lite_v3_C\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlxf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
