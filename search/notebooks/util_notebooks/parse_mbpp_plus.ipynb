{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "import json\n",
    "from search.python_utils import stringify, unstringify\n",
    "from copy import deepcopy\n",
    "from coderm.execution import smart_exec_tests_queuebatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"evalplus/mbppplus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[\"test\"]\n",
    "def replace_test(s: str) -> str:\n",
    "    CONST = \"exact_match = exp == (out is not None)\\n\"\n",
    "    assert CONST in s\n",
    "    return s.replace(CONST, CONST + \"    assert exact_match\\n\")\n",
    "\n",
    "test_data = test_data.map(lambda row, idx: {\"test\": row[\"test\"] if idx not in [318, 358, 364] else replace_test(row[\"test\"])}, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smart_exec_tests_queuebatched(test_data[\"code\"], test_data[\"test\"])\n",
    "[i for i, (stat, _) in enumerate(results) if not stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_return(s: str) -> str:\n",
    "    lines = []\n",
    "    for line in s.splitlines():\n",
    "        if line.strip().startswith(\"return \"):\n",
    "            lines.append(line[:line.index(\"return \") + len(\"return \")])\n",
    "        else:\n",
    "            lines.append(line)\n",
    "    return '\\n'.join(lines)\n",
    "        \n",
    "results = smart_exec_tests_queuebatched([replace_return(s) for s in test_data[\"code\"]], test_data[\"test\"])\n",
    "[i for i, (stat, _) in enumerate(results) if stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dicts = []\n",
    "public_test_dicts = []\n",
    "\n",
    "for i, row in enumerate(test_data):\n",
    "    fn_name = row[\"test\"].splitlines()[-1].split(\"assertion(\")[1].split(\"(*inp\")[0].strip()\n",
    "    test_dicts.append({\"inputs\": [], \"outputs\": [], \"fn_name\": fn_name, \"exec_string\": row[\"test\"].strip()})\n",
    "    public_test_dicts.append({\"inputs\": [], \"outputs\": [], \"fn_name\": fn_name, \"exec_string\": '\\n'.join(row[\"test_list\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [c.strip() for c in test_data[\"code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smart_exec_tests_queuebatched(codes, [t[\"exec_string\"] for t in test_dicts])\n",
    "[i for i, (stat, _) in enumerate(results) if not stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smart_exec_tests_queuebatched(codes, [t[\"exec_string\"] for t in public_test_dicts])\n",
    "[i for i, (stat, _) in enumerate(results) if not stat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_starter_code(s: str, fn_name: str) -> str:\n",
    "    starter_code = None\n",
    "    for line in s.splitlines():\n",
    "        if fn_name in line:\n",
    "            starter_code = line.split(\":\")[0].strip() + \":\\n    \"\n",
    "            break\n",
    "    assert starter_code is not None and starter_code.startswith(\"def \")\n",
    "    return starter_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = '\\n'\n",
    "new_test_data = deepcopy(test_data)\n",
    "new_test_data= new_test_data.rename_column(\"task_id\", \"id\")\n",
    "new_test_data = new_test_data.map(lambda row, idx: {\"starter_code\": retrieve_starter_code(codes[idx], test_dicts[idx][\"fn_name\"])}, with_indices=True)\n",
    "new_test_data = new_test_data.map(lambda row, idx: {\"solutions\": [codes[idx]]}, with_indices=True)\n",
    "new_test_data = new_test_data.map(lambda row, idx: {\"public_input_output\": json.dumps(public_test_dicts[idx])}, with_indices=True)\n",
    "new_test_data = new_test_data.map(lambda row, idx: {\"input_output\": json.dumps(test_dicts[idx])}, with_indices=True)\n",
    "new_test_data = new_test_data.map(lambda row, idx: {\"question\": row['prompt'].strip() + f\"\\n\\nYour code should pass these tests:\\n```\\n{public_test_dicts[idx]['exec_string']}\\n```\"}, with_indices=True)\n",
    "new_test_data = new_test_data.remove_columns([\"code\", \"prompt\", \"source_file\", \"test_imports\", \"test_list\", \"test\",])\n",
    "new_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DatasetDict({\"test\": new_test_data})\n",
    "dd.push_to_hub(\"codegenning/F_mbpp_plus\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlxf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
