{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69eefbef-ee3a-4611-bf2d-2131b052e3fd",
   "metadata": {},
   "source": [
    "# Pass@k curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70117480-f64b-4d78-8486-9aeb67fb3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from coderm.eval.metrics import get_pass_ks\n",
    "from coderm.utils import gunzip_json_read\n",
    "import numpy as np\n",
    "from math import comb\n",
    "import os\n",
    "import json\n",
    "\n",
    "def calcEstVar(n, k, c):\n",
    "    p = c / n\n",
    "    var = 0\n",
    "    for i in range(n+1):\n",
    "        var += comb(n-i, k) * p**i / comb(n, k) * (comb(n-k, i) * (1-p)**(n-i))\n",
    "    return var - (1-p)**(2*k)\n",
    "\n",
    "\n",
    "paths_to_results = [\n",
    "    \"sweeps/backtranslate_dsil_base\",\n",
    "    \"sweeps/backtranslate_dsil_5words\",\n",
    "    \"sweeps/backtranslate_dsil_10words\",\n",
    "    \"sweeps/backtranslate_dsil_25words\",\n",
    "    \"sweeps/backtranslate_dsil_35words\",\n",
    "    \"sweeps/backtranslate_dsil_50words\",\n",
    "    \"sweeps/backtranslate_dsil_75words\",\n",
    "    \"sweeps/backtranslate_dsil_100words\",\n",
    "    \"sweeps/backtranslate_dsil_125words\",\n",
    "    \"sweeps/backtranslate_dsil_150words\",\n",
    "    \"sweeps/backtranslate_dsil_175words\",\n",
    "    \"sweeps/backtranslate_dsil_200words\",\n",
    "    \"sweeps/backtranslate_dsil_250words\",\n",
    "    \"sweeps/backtranslate_dsil_500words\",\n",
    "    \"sweeps/backtranslate_dsil_750words\",\n",
    "    \"sweeps/backtranslate_dsil_all\",\n",
    "    # \"temp_sweeps/backtranslate_base\",\n",
    "    # \"temp_sweeps/backtranslate_5words\",\n",
    "    # \"temp_sweeps/backtranslate_10words\",\n",
    "    # \"temp_sweeps/backtranslate_25words\",\n",
    "    # \"temp_sweeps/backtranslate_35words\",\n",
    "    # \"temp_sweeps/backtranslate_50words\",\n",
    "    # \"temp_sweeps/backtranslate_75words\",\n",
    "    # \"temp_sweeps/backtranslate_100words\",\n",
    "    # \"temp_sweeps/backtranslate_125words\",\n",
    "    # \"temp_sweeps/backtranslate_150words\",\n",
    "    # \"temp_sweeps/backtranslate_175words\",\n",
    "    # \"temp_sweeps/backtranslate_200words\",\n",
    "    # \"temp_sweeps/backtranslate_250words\",\n",
    "    # \"temp_sweeps/backtranslate_500words\",\n",
    "    # \"temp_sweeps/backtranslate_750words\",\n",
    "    # \"temp_sweeps/backtranslate_all\",\n",
    "]\n",
    "compare = [\n",
    "    # \"test_results/simpleidea_small_temp0.4\",\n",
    "    # \"test_results/simpleidea_small_temp0.5\",\n",
    "    # \"test_results/simpleidea_small_temp0.6\",\n",
    "]\n",
    "from pathlib import Path\n",
    "for p in paths_to_results + compare:\n",
    "    assert Path(p).exists(), f\"Path {p} doesn't exist!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_solution_length = {}\n",
    "\n",
    "for path in paths_to_results:\n",
    "    if \"base\" in path:\n",
    "        avg_solution_length[path] = 0. \n",
    "        continue\n",
    "\n",
    "    log_path = os.path.join(\"logs\", path)\n",
    "    query_path = os.path.join(log_path, \"queries\")\n",
    "\n",
    "    solution_files = [f for f in os.listdir(query_path) if f.startswith(\"solution\")]\n",
    "    solution_path = None\n",
    "    for solution_file in solution_files:\n",
    "        solution_path = os.path.join(query_path, solution_file)\n",
    "        print(f\"Found solution file: {solution_path}\")\n",
    "    \n",
    "    assert solution_path is not None\n",
    "\n",
    "    with open(solution_path, \"r\") as solution_file:\n",
    "        solutions = json.load(solution_file)\n",
    "    \n",
    "    num_tokens_list = [e[\"completion\"][\"num_tokens\"] for e in solutions]\n",
    "    avg_tokens = sum(num_tokens_list) / len(num_tokens_list)\n",
    "    avg_solution_length[path] = avg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab78162",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_solution_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061673e-4bb8-4785-aabe-106c73c5c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pass_ks = {}\n",
    "for r in (paths_to_results + compare):\n",
    "    print(f\"Reading\", r)\n",
    "    items = gunzip_json_read(r)[\"items\"]\n",
    "    upper_k = len(items[0][\"results\"])\n",
    "    pass_ks = {}\n",
    "    for k in range(1, upper_k+1):\n",
    "        pass_ks[k] = np.mean(get_pass_ks(items, k))\n",
    "    all_pass_ks[r] = pass_ks\n",
    "\n",
    "all_std = {}\n",
    "for r in (paths_to_results + compare):\n",
    "    print(f\"Reading\", r)\n",
    "    items = gunzip_json_read(r)[\"items\"]\n",
    "    upper_k = len(items[0][\"results\"])\n",
    "    \n",
    "    vars = []\n",
    "    for item in items:\n",
    "        single_problem = []\n",
    "        for k in range(1, upper_k+1):\n",
    "            single_problem.append(calcEstVar(len(items[0][\"results\"]), k, sum(i[\"passing\"] for i in item[\"results\"])))\n",
    "        vars.append(single_problem)\n",
    "\n",
    "    vars = np.array(vars)\n",
    "    all_std[r] = np.sqrt(np.sum(vars, axis=0) / len(items) ** 2) * 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eea1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "select_ones = paths_to_results[1:]\n",
    "select_ones = paths_to_results\n",
    "\n",
    "plot_line = [[avg_solution_length[label], all_pass_ks[label][1], all_std[label][0]] for label in select_ones]\n",
    "plot_line = np.array(sorted(plot_line))\n",
    "plt.plot(plot_line[:, 0]+1, plot_line[:, 1], linestyle='-', label='Pass@1', marker='o')\n",
    "plt.fill_between(plot_line[:, 0]+1, plot_line[:, 1] - plot_line[:, 2], plot_line[:, 1] + plot_line[:, 2], alpha=0.2)\n",
    "\n",
    "plot_line_pa5 = [[avg_solution_length[label], all_pass_ks[label][5], all_std[label][4]] for label in select_ones]\n",
    "plot_line_pa5 = np.array(sorted(plot_line_pa5))\n",
    "plt.plot(plot_line_pa5[:, 0]+1, plot_line_pa5[:, 1], linestyle='-', label='Pass@5', marker='o')\n",
    "plt.fill_between(plot_line_pa5[:, 0]+1, plot_line_pa5[:, 1] - plot_line_pa5[:, 2], plot_line_pa5[:, 1] + plot_line_pa5[:, 2], alpha=0.2)\n",
    "\n",
    "# for label in all_pass_ks:\n",
    "#     plot_line.append()\n",
    "#     # ks = list(values.keys())\n",
    "#     # pass_at_k = list(values.values())\n",
    "#     std_devs = list(all_std[label])\n",
    "#     linestyle = '--' if any(p in label for p in paths_to_results) and len(compare) > 0 else '-'\n",
    "#     plt.plot\n",
    "#     plt.plot(ks, pass_at_k, label=Path(label), linestyle=linestyle)\n",
    "#     plt.fill_between(ks, np.array(pass_at_k) - np.array(std_devs), np.array(pass_at_k) + np.array(std_devs), alpha=0.2)\n",
    "\n",
    "plt.xlabel('Avg Solution Token Length (+1)')\n",
    "# plt.xscale('symlog', linthresh=20)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Pass@1')\n",
    "plt.title('Pass@1 and Pass@5 vs avg solution token length in backtranslation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "\n",
    "items = gunzip_json_read(\"test_results/simpleidea_small\")[\"items\"]\n",
    "for item in items:\n",
    "    trials = []\n",
    "    for trial in item[\"results\"]:\n",
    "        trials.append(trial[\"passing\"])\n",
    "    ps.append(sum(trials) / len(trials))\n",
    "\n",
    "plt.hist(ps)\n",
    "sorted(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b20253-30ec-4394-93c8-e69d0b72d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for label, values in all_pass_ks.items():\n",
    "    ks = list(values.keys())\n",
    "    pass_at_k = list(values.values())\n",
    "    std_devs = list(all_std[label])\n",
    "    linestyle = '--' if any(p in label for p in paths_to_results) and len(compare) > 0 else '-'\n",
    "    plt.plot(ks, pass_at_k, label=Path(label), linestyle=linestyle)\n",
    "    plt.fill_between(ks, np.array(pass_at_k) - np.array(std_devs), np.array(pass_at_k) + np.array(std_devs), alpha=0.2)\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Pass@k')\n",
    "plt.title('Pass@k vs k for different models')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbee551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate paths for the 25 result files\n",
    "idea_temps = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "code_temps = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "heatmap_data = np.zeros((len(idea_temps), len(code_temps)))\n",
    "\n",
    "sel_k = 90\n",
    "for i, it in enumerate(idea_temps):\n",
    "    for j, ct in enumerate(code_temps):\n",
    "        path = f\"sweeps/simpleidea_small_it{it}_ct{ct}\"\n",
    "        if not Path(path).exists():\n",
    "            pass_ks = 0\n",
    "        else:\n",
    "            items = gunzip_json_read(path)[\"items\"]\n",
    "            pass_ks = np.mean(get_pass_ks(items, sel_k))\n",
    "        heatmap_data[i, j] = pass_ks\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(heatmap_data, cmap='plasma', origin='lower')\n",
    "plt.colorbar(label=f'Pass@{sel_k}')\n",
    "plt.xticks(ticks=np.arange(len(code_temps)), labels=code_temps)\n",
    "plt.yticks(ticks=np.arange(len(idea_temps)), labels=idea_temps)\n",
    "plt.xlabel('Code Temperature (ct)')\n",
    "plt.ylabel('Idea Temperature (it)')\n",
    "plt.title(f'Pass@{sel_k} Heatmap for Different Temperatures')\n",
    "\n",
    "# Function to determine text color based on brightness\n",
    "def get_text_color(value, cmap):\n",
    "    norm = plt.Normalize(vmin=heatmap_data.min(), vmax=heatmap_data.max())\n",
    "    rgba = cmap(norm(value))\n",
    "    brightness = 0.299 * rgba[0] + 0.587 * rgba[1] + 0.114 * rgba[2]\n",
    "    return 'black' if brightness > 0.5 else 'white'\n",
    "\n",
    "cmap = plt.get_cmap('plasma')\n",
    "for i in range(len(idea_temps)):\n",
    "    for j in range(len(code_temps)):\n",
    "        text_color = get_text_color(heatmap_data[i, j], cmap)\n",
    "        plt.text(j, i, f\"{heatmap_data[i, j]:.2f}\", ha='center', va='center', color=text_color, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2626ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166888ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_results/temp.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94306e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
